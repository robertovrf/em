::::::::::::::::::::DISTRIBUTED ARCH DESCRIPTION::::::::::::::::::::

* local ip: is self explanatory (the distributor needs this to pass this address to the remote machine, so the remote machine can connect back to the local machine in case the function call has object references).

* local port: is the first port used by the local machine to create reverse proxies that represents object references. 

* |localip:localport, remoteip:remoteport, remoteip:remoteport|complist|comprelations|

NOTE: This only works if you relocate/replicate one interface at a time (if it is multiple than it won't work -- we would need to expand it to know the list of ips for the different relocated interfaces + the portManager has to coordinate the ports better). I have to bear this in mind for the real version of the relocate framework.

::::::::::::::::::::PORTS IN THE DISTRIBUTED SYSTEM::::::::::::::::::::

2013 - is the port for the root component HTTPGETREMOTE (the one that runs on remote machines)
2014 - is the first port used to create proxies (the servers on the client side --- i.e. the ones that represents the original reference passed on to the remote machine), the proxies are going to be used from 2014 onwards.
NOTE THAT: on the server side (i.e. the machine where we relocated components) only has the root component bound to a port, it does not have to create server proxies to be bound in any port. Unless the machine decides to relocate components itself. Then it'll have to use ports to bind the proxies that will represent the original object reference. In this last case scenario I won't be able to experiment everything locally.

::::::::::::::::::::REDIR::::::::::::::::::::

redir --lport=3306 --laddr=scc-mc10.lancs.ac.uk --cport=3306 --caddr=localhost

redir --lport=3306 --laddr=scc-mc1.lancs.ac.uk --cport=3306 --caddr=localhost

redir --lport=3306 --laddr=scc-mc2.lancs.ac.uk --cport=3306 --caddr=localhost


::::::::::::::::::::REDIR::::::::::::::::::::




::::::::::::::::::::DOCKER::::::::::::::::::::

download image -- note there is a list of available version at https://hub.docker.com/_/mysql (latest is one of the version, another one is 5.7.30): sudo docker pull mysql/mysql-server:latest

list images: sudo docker images

run docker image and attach the port 3306 from the host to 3306 of the image: docker runâ€Š--name=mydb -e MYSQL_ROOT_HOST=% -p 3306:3306 -d mysql/mysql-server:5.7.30

sudo docker run --name=mydb -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 -d mysql/mysql-server:5.7.30 

sudo docker run --name=em -p 2020:2020 -d robertovrf/emergent-microservice:all 


sudo docker run --name=mydb -e MYSQL_ROOT_HOST=% -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 -d mysql/mysql-server:5.7.30

stop and delete image: docker stop mysql4 && docker rm mysql4

check the automatically generated password of root user, copy it: docker logs mysql1 2>&1 | grep GENERATED

listing running ports: sudo lsof -i -P -n | grep LISTEN

sudo service mysql status

sudo service mysql stop

sudo service mysql start

docker exec -it mydb bash

docker exec -it em-hpa bash




COMANDOS para rodar o interscity

Creating the different images to run on the google cloud infra: sudo docker build -t em:all -f- . < interscity_dana_project/configs/docker/Dockerfile

running my created image locally:  sudo docker run --name=emergentsys -p 2020:2020 -d em:all





docker build -t ews:1.0 -f- . < emergent_web_server/Docker/Dockerfile

docker run --name=ews -p 2011-2012:2011-2012 -d ews:1.0

docker run --name=ews -p 2011-2012:2011-2012 -d robertovrf/ews:1.0


docker exec -it ews bash

docker rmi $(docker images -q)

docker rmi robertovrf/ews:1.0

docker stop $(docker ps -a -q)

docker rm $(docker ps -a -q)

docker tag ews:1.0 robertovrf/ews:1.0

docker push robertovrf/ews:1.0



sudo docker run --name=em-hpa -p 2020:2020 -d em-hpa:default

removes all containers that are stopped: sudo docker container prune

lists running containers: sudo docker container ls

list containers (including the ones stoopped): sudo docker ps -a

getting logs from containers: sudo docker container logs <container-ID>


CREATE DOCKER IMAGE AND PUSHING IT TO DOCKER HUB
FIRST docker login
LAST docker logout

this should be run after build: sudo docker build -t emergent-microservice:all -f- . < path/to/Dockerfile
creating a name-space for the image: sudo docker tag emergent-microservice:all robertovrf/emergent-microservice:all

DUMP BD
kubectl exec -it podName -- mysql -u root -proot < complete_dump.sql

sending image to hub: sudo docker push robertovrf/emergent-microservice:all


gcloud container clusters get-credentials cluster-1 --zone us-central1-c --project interscity

(tem que criar o interscity-dana-nopal-nomysql1.yaml)
kubectl apply -f interscity-dana-nopal-nomysql1.yaml


kubectl delete deployment interscity-dana-nopal-nomysql1

kubectl delete --all pods

kubectl get deployments --all-namespaces

kubectl delete deployment interscity-dana-no-pal-nomysql1

kubectl run --image=mysql/mysql-server:8.0 mydb --port=3306 --env="MYSQL_ROOT_HOST=%" --env="MYSQL_ROOT_PASSWORD=root"

kubectl expose pod mydb --type LoadBalancer --port 3306 --target-port 3306

// mysql
kubectl expose deployment mydb --type LoadBalancer --port 3306 --target-port 3306

// metric server
kubectl expose deployment metric-server --type LoadBalancer --port 2006 --target-port 2006

// emergent-servicer-notifier
kubectl expose deployment emergent-microservice --type LoadBalancer --port 2020 --target-port 2020

//postgresql
kubectl expose deployment mydb --type LoadBalancer --port 5432 --target-port 5432

Postgres:
psql

psql --username=mydb -W

\l (show databases;)
\dt (show tables;)


kubectl expose deployment emergent-microservice --type LoadBalancer --port 2020 --target-port 2020

kubectl expose deployment sd-exporter --type LoadBalancer --port 8081 --target-port 8081

kubectl expose deployment load-balancer --type LoadBalancer --port 2012 --target-port 2012

kubectl scale deployments/emergent-microservice --replicas=5


kubectl exec -it mydb -- /bin/bash

kubectl exec -it em-hpa -- /bin/bash


kubectl create deployment --image=mysql/mysql-server:8.0 mydb --port=3306 --env="MYSQL_ROOT_HOST=%" --env="MYSQL_ROOT_PASSWORD=root"

kubectl cp emergent-microservice-6b6b7c7cf4-pkfdz:/home/roberto/interscity_dana_project/pal/em.log em.log


AUTOSCALER

kubectl get deployments


kubectl describe hpa

COMANDO QUE EU ESQUECIIII --->>>>
BEFORE CREATING THE HPA AND THE DEPLOYMENTS WE NEED TO EXECUTE THESE TWO COMMANDS: ----

kubectl create clusterrolebinding cluster-admin-binding \
    --clusterrole cluster-admin --user "$(gcloud config get-value account)"

kubectl apply -f https://raw.githubusercontent.com/GoogleCloudPlatform/k8s-stackdriver/4ed2ef2a60212f07727370baaecf505d8b2ce678/custom-metrics-stackdriver-adapter/deploy/production/adapter_new_resource_model.yaml

----------------------------

kubectl scale --replicas=1 -f interscity-dana-withpal-nomysql1.yaml


kubectl delete hpa emergent-microservice-hpa



================= Docker=============================
# To clean local Docker image registry
sudo docker system prune -a
sudo docker rmi 'docker-images -q' (this command didn't work!!)

# To create the Interscity-InteractiveAssembly Docker image
sudo docker build -t marciopsa/interscity_pal_k8s_1 .

# To test the Interscity-InteractiveAssembly Docker image locally
sudo docker run -it marciopsa/interscity_pal_k8s_1 /bin/bash

# To push the Interscity-InteractiveAssembly Docker image to Docker Hub
docker login -u "username" -p "userpassword"
docker push marciopsa/interscity_pal_k8s_1

# To deploy the Interscity-InteractiveAssembly Docker image (our app) on Kubernetes (GKE)

kubectl run docker-interscity-pal3 --image docker.io/marciopsa/interscity_pal_k8s_1 --port 2020

# To create a Kubernetes Service from the Interscity-InteractiveAssembly deployment on Kubernetes (GKE)
kubectl expose deployment docker-interscity-pal3 --type LoadBalancer --port 2020 --target-port 2020

# Getting the Interscity-InteractiveAssembly App's external IP created by GKE
kubectl get services

# To create a HPA (Horizontal Pod Autoscaler) using default metrics (cpu use)
kubectl autoscale deployment docker-interscity-pal4 --max 10 --min 1 --cpu-percent 50

# To verify the working of HPA
kubectl get hpa

# To verify and identify all Pods running.
kubectl get pods

# To examine the execution of one Pod
kubectl exec -it [pod-id] -- /bin/bash


# emergent server
docker build -t emergent-microservice:all -f- . < interscity_dana_project/config/docker/emergent-microservice-all/Dockerfile
docker tag emergent-microservice:all robertovrf/emergent-microservice:all 
docker push robertovrf/emergent-microservice:all

# metric server
docker build -t metric-server:1.0 -f- . < interscity_dana_project/config/docker/metric-server/Dockerfile
docker tag metric-server:1.0 robertovrf/metric-server:1.0 
docker push robertovrf/metric-server:1.0

# emergent server hpa notifier
docker build -t em-all:notifier -f- . < interscity_dana_project/config/docker/emergent-microservice-hpa-notifier/Dockerfile
docker tag em-all:notifier robertovrf/em-all:notifier
docker push robertovrf/em-all:notifier

# emergent server hpa notifier cache
docker build -t em-all:nc -f- . < interscity_dana_project/config/docker/emergent-microservice-hpa-notifier/Dockerfile
docker tag em-all:nc robertovrf/em-all:nc
docker push robertovrf/em-all:nc




kubectl rollout



======================== dana commands =================
# To compile the whole project
dnc . -sp ../pal

# To run MySQL of Data Collector (port 2022)
~/git/k8s_emergent_systems_integration/MySQL_of_DC/interscity_dana_project/pal$ dana -sp ../dc/ InteractiveAssembly.o ../../dana/compone
nts/ws/core.o -p 2022

# To run Data Collector (port 2020)
~/git/k8s_emergent_systems_integration/interscit_dana_no_pal2 _noMySQL/interscity_dana_project/pal$
dana -sp ../dc/ InteractiveAssembly.o ../../dana/components/ws/core.o -p 2020

dana -sp ../dc/ EmergentSys.o ../../../dana/components/ws/core.o -p 2020

# To run Test App
~/git/k8s_emergent_systems_integration/interscit_dana_no_pal2 _noMySQL/interscity_dana_project/clients/app_test_kubernetes1$ dana app_test_k8s2.o



Espero que ajude.




::::::::::::::::::::PEL Queries that was tested!::::::::::::::::::::

1)
add_proxy |../metacom/monitoring/proxies/HTTPProxy.o|*(*:HTTPHandler[0]:*)|

2)
add_proxy |../metacom/monitoring/proxies/HTTPProxy.o|1(*:HTTPHandler[0]:*)|

3)
add_proxy |../web_server/http/HTTPProtocol.o,../metacom/monitoring/proxies/HTTPProxy.o|1(0:HTTPHandler[1]:*)|

4)
add_proxy |../web_server/request/RequestHandler.o,../web_server/http/HTTPProtocol.o,../metacom/monitoring/proxies/HTTPProxy.o|1(0:HTTPProtocol:1,1:HTTPHandler[2]:*)|

5)
add_proxy |../web_server/request/RequestHandlerPT.o,../web_server/http/HTTPProtocol.o,../metacom/monitoring/proxies/HTTPProxy.o|*(0:HTTPProtocol:1,1:HTTPHandler[2]:*)|

6)
add_proxy |../metacom/monitoring/proxies/LBProxy.o|*(*:LBHandler[0]:*)|

7)
add_proxy |../metacom/monitoring/proxies/HTTPProxy.o|*(*:http.handler.GET.HTTPGET[0]:*)|
add_proxy |../pal/monitoring/proxies/HTTPProxy.o|*(*:http.handler.GET.HTTPGET[0]:*)|

add_proxy |../pal/monitoring/proxies/NeuralNetProxy.o|*(*:OutputLayer[0]:*)|



8)
add_proxy |../metacom/monitoring/proxies/MetricProxy.o|*(*:HTTPHeader[0]:*)|

9)
add_proxy |../metacom/monitoring/proxies/CacheProxy.o|*(*:CacheHandler[0]:*)|

The following query does not work in this current version, but might in the future.
1)
add_proxy |../web_server/request/RequestHandlerPT.o,../metacom/monitoring/proxies/HTTPProxy.o|1(0:HTTPProtocol:*,*:HTTPHandler[1]:*)|
-> the reason why this doesn't work is because there is * in the binding exp that is not the last one. The idea behind this is that you would add a path/an exact string with all the exact bindings that comes before the binding exp where the proxy should be placed at. 

::::::::::::::::::::Queries to be tested!::::::::::::::::::::

-> make some exp with &
-> make some exp with ;
-> makes ome exp with & and ;




ERRORs:

assembly> dana: symbol lookup error: /home/roberto/dana/resources-ext/MySQLLib[deb.x64].dnl: undefined symbol: OPENSSL_init_ssl


Segmentation fault











Allowing third-party apps to MAC!
sudo spctl -â€“master-disable








apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    run: mydb
  name: mydb
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      run: mydb
  template:
    metadata:
      labels:
        run: mydb
    spec:
      containers:
      - command: 
        image: postgres:10.1
        name: mydb
        ports:
        - containerPort: 5432
        resources:
          requests:
            cpu: 900m
        env:
          - name: POD_ID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: POSTGRES_PASSWORD
            value: mydb
          - name: POSTGRES_USER
            value: mydb




